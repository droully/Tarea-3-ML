{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 3 - Ensamblados y modelos avanzados </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Técnicas de ensamblado: *bagging*, *boosting*, *random forest*.\n",
    "* Redes Neuronales Convolucionales vs *Feed Forward*\n",
    "* Aprendizaje no supervisado: *hidden models*\n",
    "* Aprendizaje sobre secuencias\n",
    " \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: 21 de Diciembre (11:55 hrs)\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea3-INF393-II-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Calidad de un vino  \n",
    "[2.](#segundo) Redes Convolucionales sobre imágenes  \n",
    "[3.](#tercero) Cadenas de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Calidad de un vino\n",
    "---\n",
    "\n",
    "Existen muchas variedades de vino existentes debido a los distintos gustos que tienen las personas. Del gusto se desprende la calidad que una persona le podría asignar a un vino, el cual proviene del gusto de la persona en particular, o bien, a la gran cantidad de quı́micos y procesos que se aplican a la producción de vino. Para el área de negocios, el estimar cuál es la calidad de un vino en base a la apreciación del público es una tarea bastante difı́cil.  \n",
    "Para esta actividad se trabajará con dos *datasets* asociados a las variantes tinto y blanco del vino portugués\n",
    "”Vinho Verde”[[1]](#refs). Debido a temas privados solo se cuenta con las caracterı́stcas fisioquı́micas asociadas a un\n",
    "vino en particular, los cuales corresponden a 11 atributos numéricos descritos en el siguiente __[link](http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names)__.\n",
    "\n",
    "Este problema puede ser abordado como clasificación de 11 clases o de regresión, ya que el atributo a estimar,\n",
    "*quality*, tiene un dominio como valor entero 0 y 10. La forma de resolverlo será a través de **ensamblados**.\n",
    "\n",
    "<img src=\"https://uploads.toptal.io/blog/image/92064/toptal-blog-image-1454584112948-fc1d35939aa1886bf30c816b3ac20e21.jpg\" title=\"Title text\" width=\"20%\"  />\n",
    "\n",
    "\n",
    "> a) Carge los dos dataset en un único dataframe de pandas, además de agregar una columna indicando si es vino tinto o blanco. Describa el dataset a trabajar.\n",
    "```python\n",
    "import pandas as pd\n",
    "df_red = pd.read_csv(\"winequality-red.csv\",sep=\";\")\n",
    "df_white = pd.read_csv(\"winequality-white.csv\",sep=\";\")\n",
    "df = pd.concat([df_red,df_white], axis=0)\n",
    "...#genere atributo 'tipo'\n",
    "```\n",
    "\n",
    "> b) Aborde este problema como si fuera de clasificación con multiples clases para predecir el valor de calidad de un vino, es decir, utilice las distintas caracterı́sticas fisioquı́micas presentes en los datos para estimar la etiqueta ¿Cuántas clases son y cuántos ejemplos hay por clase? ¿Qué sucede con predecir si un vino tiene calidad mínima (0) o máxima(10)? Además para el propósito académico de esta actividad cree un conjunto de pruebas (20%)  para evaluar la generalización final del modelo y otro de validación (20%) si estima conveniente. \n",
    "```python\n",
    "y = df[\"quality\"].values #or codify\n",
    "...#train and test split over df\n",
    "```\n",
    "\n",
    "> c) Entrene un solo Árbol de Clasificación de múltiples niveles para resolver el problema. Defina un Árbol **no regularizado** (como el que no tiene límites en su profundidad) y otro Árbol **regularizado** (variando los hiper-parámetros que prefiera, por ejemplo, los más comunes como la profundidad, el número mínimo de datos para realizar *split* o el número mínimo de datos en cada hoja), recuerde que las **decisiones** no pueden ser basadas mirando el conjunto de pruebas. Debido al desbalanceo que se produce en las clases mida la métrica F1-score [[2]](#refs) sobre el conjunto de entrenamiento y de pruebas.\n",
    "\n",
    "\n",
    "> d) Entrene un ensamblado de árboles de múltiples niveles, mediante la técnica de **Bagging**, compare el Árbol **no regularizado** con el **regularizado** (*seteando los hiper-parámetros en base a lo experimentado anteriormente en c)*) ¿Qué debería suceder? ¿Se visualiza *overfitting*? Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del F1-score de entrenamiento y de pruebas en función de este hiper-parámetro.\n",
    "```python\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = BaggingClassifier(base_estimator=Tree(max_depth=), n_estimators=, n_jobs=-1)\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = model.predict(x)\n",
    "f1_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "> e) Entrene un ensamblado de árboles de múltiples niveles, mediante la técnica de **AdaBoost**, compare el Árbol **no regularizado** con el **regularizado** (*seteando los hiper-parámetros en base a lo experimentado anteriormente en c)* ¿Se visualiza *overfitting*? ¿Qué técnica se utiliza, *re-muestrear* o *pesar* ejemplos? ¿Qué le parece más sensato?. Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen del F1-score de entrenamiento y de pruebas en función de este hiper-parámetro. Compare y analice con la técnica utilizada en d).\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(base_estimator=Tree(max_depth=), n_estimators=)\n",
    "```\n",
    "\n",
    "> f) Pruebe otra técnica de ensamblado dedicada a árboles de decisión, que combina el muestreo *boostrap* de *Bagging* con muestreo sobre las *features*: **Random Forest**, compare el Árbol **no regularizado** con el **regularizado** ¿Se visualiza *overfitting*?. Varíe la cantidad de árboles de decisión utilizados en el ensamblado (*n estimators*), realice un gráfico resumen el F1-score de entrenamiento y de pruebas en función de este hiper-parámetro.\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=, max_depth=,n_jobs=-1)\n",
    "```\n",
    "\n",
    "> g) Verifique que el **OOB error** (*out of bag error*) de los ensambladores que utilizan la técnica *boostrap* puede ser una alternativa como métrica de generalización, compárelo con el error calculado sobre el conjunto de pruebas y validación (o en su defecto *cross validation*).\n",
    "```python\n",
    "oob_error = 1 - model.oob_score_\n",
    "test_error = 1- model.score(X_test,y_test)\n",
    "val_error = 1- model.score(X_val,y_val)\n",
    "print(\"OOB error: \",oob_error)\n",
    "print (\"Val error: \",val_error)\n",
    "print(\"Test error: \",test_error)\n",
    "```\n",
    "\n",
    "> h) Entrene alguna otra máquina de aprendizaje, elegida por usted de entre todas las vistas en el curso, para resolver el problema. Elija los hiper-parámetros que estime convenientes intentando aumentar el *F1-scor*e obtenido por los algoritmos anteriores ¿Se logra una mejora? ¿Por qué?\n",
    "\n",
    "> i) Compare y analice las distintas maneras con las que se resolvió el problema definido en b), por ejemplo incluya las decisiones que conlleva y los resultados que reflejan.\n",
    "\n",
    "> j) Defina otra forma de combinar los valores que entregan los ensamblados al hacer predicciones y compare con lo que se hace actualmente, por ejemplo *Bagging* realiza el voto de la mayoría para clasificación y promedio para regresión, *AdaBoost* realiza una combinación ponderada de cada clasificador dependiendo de su *habilidad* (desempeño para clasificar el conjunto de entrenamiento).\n",
    "```python\n",
    "def combine_predictions(predictions):\n",
    "    return #define !\n",
    "list_estimators = model.estimators_\n",
    "list_predictions = [estimator.predict(X_test) for estimator in list_estimators]\n",
    "new_predictions = combine_predictions(list_predictions)\n",
    "...#measure f1 score\n",
    "f1_score(y_test, new_predictions)\n",
    "```\n",
    "\n",
    "> k) Utilice la técnica de ensamblado para seleccionar características, para ésto defina un criterio para estimar la importancia de los distintos atributos en el ensamblado, impleméntelo sobre alguno de los ensambladores entrenados para resolver el problema definido en b). Realice un *ranking* de importancia de atributos y seleccione las $k$ características más relevantes.\n",
    "\n",
    "> l) Entrene la máquina de aprendizaje definida en h) sobre las $k$ carecterísticas derivadas del punto anterior ¿Mejora los resultados sobre ésta máquina de aprendizaje?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Redes Convolucionales sobre imágenes\n",
    "---\n",
    "Las redes neuronales hoy en día han sido extendidas a numerosas aplicaciones gracias a la arquitectura definida para cada tipo de problema. Las redes neuronales que aplican la operación de convolución [[3]](#refs) o convoluciones en sus capas son concidas como *CNN* o *ConvNets*, lo cual se especializa en trabajar en datos con forma matricial (ya sea bi-dimensional o tri-dimensional), lo cual se adecúa perfectamente a imágenes (matrices), ya que gracias a su conectividad local se especializan en reconocer patrones sobre los datos de manera espacial, como refleja la siguiente imagen:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*N4h1SgwbWNmtrRhszM9EJg.png\" title=\"Title text\" width=\"90%\" />\n",
    "\n",
    "\n",
    "En esta actividad trabajará con un extracto bastante pequeño del dataset conocido como **101-Food**[[4]](#refs), el cual consta de mil imágenes pertenecientes a 3 clases (*Hambuger, Hot Dog* y *Pizza*) separados en conjunto de entrenamiento y validación.  \n",
    "El extracto pequeño del dataset con el que se trabajará deberá ser descargado del siguiente __[link](https://www.dropbox.com/s/56xqazmhbh0doi7/food_data.zip?dl=0)__ a través de Dropbox.\n",
    "\n",
    "> a) Construya funciones para leer los datos y cargarlos al momento de entrenar (durante cada *epoch*), para ésto utilice *Image Data Generator* de keras.\n",
    "```python\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #no transformation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'food_data/train',\n",
    "        target_size=(150, 150),\n",
    "        color_mode='rgb',\n",
    "        batch_size=32)\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'food_data/val',\n",
    "        target_size=(150, 150),\n",
    "        color_mode='rgb',\n",
    "        batch_size=32)\n",
    "```\n",
    "\n",
    "> b) Utilice la red tradicional (*Feed Forward*) entregada en el código para ser entrenada sobre los datos vectorizados, esto es que cada imagen queda representada como un vector gigante, y las 3 clases a las que se enfrenta. Evalúe el modelo con la métrica *accuracy* sobre el conjunto de validación.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_generator.image_shape)) #full dense\n",
    "model.add(BatchNormalization()) #to normalize the input..\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu')) #128\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # Let's train the model using RMSprop\n",
    "model.summary()\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator.classes)//train_generator.batch_size, #samples//batch_size\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator.classes)//validation_generator.batch_size)\n",
    "print(\"Accuracy validation: \",model.evaluate_generator(generator=validation_generator)[1])\n",
    "```\n",
    "\n",
    "> c) Utilice la red convolucional (**CNN**) entregada en el código para ser entrenada sobre los datos brutos, matrices RGB de píxeles, y las 3 clases a las que se enfrenta. Evalúe el modelo con la métrica *accuracy* sobre el conjunto de validación. Compare.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=train_generator.image_shape,activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(len(train_generator.class_indices),activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # Let's train the model using RMSprop\n",
    "model.summary()\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator.classes)//train_generator.batch_size, #samples//batch_size\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator.classes)//validation_generator.batch_size)\n",
    "```\n",
    "\n",
    "> d) Genere un conjunto datos con incorrecta etiquetación de manera manual y vea si el modelo convolucional se sigue comportando de la misma manera. Para esto tome 100 imágenes aleatorias de entrenamiento de la carpeta *hot dog* y 100 imágenes aleatorias de entrenamiento de la carpeta *hamburger* e intercambielas, sin manipular las imágenes de la carpeta *pizza* y con el conjunto de validación intacto. Genere las matrices de confusión en el conjunto de validación para visualizar cómo afectó al modelo la corrupción realizada a los datos.\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix \n",
    "Y_pred = model.predict_generator(validation_generator,len(validation_generator.classes)//validation_generator.batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "confusion_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. [Opcional] Cadenas de Markov\n",
    "---\n",
    "> *Dado que esta actividad es opcional, el puntaje obtenido si se realiza será equivalente a un bonus sobre el promedio final de notas de tareas.*\n",
    "\n",
    "En esta sección emplearemos un modelo **no supervisado** especializado en secuencias, como lo son las cadenas de markov, para modelar series de tiempo, es decir una serie de registros (tı́picamente valores reales) regularmente indexados en el tiempo. Parea ello utilizaremos el dataset denominado “*international airline passengers*” [[5]](#refs). La tarea consiste en predecir el número de pasajeros (miles) en vuelos internacionales.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/Fyf0LK6.png\" title=\"Title text\" width=\"80%\" />\n",
    "\n",
    "Los datos pueden ser descargados a través del siguiente __[link](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line)__. También están disponibles en Kaggle a través del siguiente __[link](https://www.kaggle.com/andreazzini/international-airline-passengers)__\n",
    "\n",
    "Para la actividad se trabajará con la librería de *sklearn* para aprendizaje sobre secuencias HMM (*Hidden Markov Model*), también puede acudir a la documentación online a través del siguiente __[link](https://hmmlearn.readthedocs.io/en/latest/tutorial.html#available-models)__.\n",
    "```\n",
    "pip install --upgrade hmmlearn\n",
    "conda install -c omnia hmmlearn\n",
    "```\n",
    "\n",
    "> a) Escriba una función que cargue los datos, los divida en conjuntos de entrenamiento y de pruebas. En base a como trabajan las cadenas de markov ¿Es necesario escalar los datos?\n",
    "```python\n",
    "import pandas as pd\n",
    "name_f = \"international-airline-passengers.csv\"\n",
    "dataframe = pd.read_csv(name_f,sep=',',usecols=[1],engine='python',skipfooter = 3)\n",
    "dataframe[:] = dataframe[:].astype('float32')\n",
    "X_train, X_test = dataframe[:96].values, dataframe[96:].values\n",
    "```\n",
    "\n",
    "\n",
    "> b) Para resolver el problema defina un modelo de cadena de markov de primer orden con estados ocultos (*hidden markov model*) simple con un generador de datos osbervados que e distribuye normal $p(x_t|s_t)=\\mathcal{N}(\\mu_{s},\\sigma_{s})$. Para evaluar mida la log-verosimilitud (*log-likelihood*) del modelo sobre el conjunto de entrenamiento y de pruebas. Comente\n",
    "```python\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "np.random.seed(30)\n",
    "n_state = 3\n",
    "markov_model = hmm.GaussianHMM(n_components=n_state, n_iter=100)\n",
    "markov_model.fit(X_train)\n",
    "markov_model.score(X_train)\n",
    "markov_model.score(X_val)\n",
    "```\n",
    "\n",
    "> c) Analice cualitativamente lo que aprendió el modelo a través de las distribuciones de probabilidad de las observaciones para un estado oculto dado, esto es, $p(x_t|s_t)$, y las distribuciones de probabilidad de transición $p(s_{t+1}|s_t)$. Comente.\n",
    "```python\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import itertools\n",
    "for i in range(n_state):\n",
    "    r = norm(markov_model.means_[i], np.sqrt( markov_model.covars_[i,0])).rvs(10000)\n",
    "    sns.distplot(r,kde=True, hist=False,label=\"Estado \"+str(i))\n",
    "plt.legend()\n",
    "plt.title(\"Distribuciones de cada estado\")\n",
    "plt.show()\n",
    "def plot_state_matrix(cm, states,title='Transition Probabilities',cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(states))\n",
    "    plt.xticks(tick_marks, states)\n",
    "    plt.yticks(tick_marks, states)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
    "    plt.ylabel('Origin state')\n",
    "    plt.xlabel('Destination state')\n",
    "    plt.tight_layout()\n",
    "plot_state_matrix(markov_model.transmat_,np.arange(n_state))\n",
    "```\n",
    "\n",
    "> d) Gracias a que el modelo no predice un valor único, sino que una distribucipon de probabilidad (incerteza en cada valor continuo), realice un gráfico de ésto, es decir, visualice el intervalo de confianza en que el modelo predice en cada instante de tiempo, dado el estado oculto, y contrarréstelo con la secuencia original. Hágalo para el conjunto de entrenamiento y de pruebas\n",
    "```python\n",
    "X_state = markov_model.predict(X) #predice el estado, no el valor\n",
    "plt.fill_between(np.arange(X.shape[0]),markov_model.means_[X_state][:,0]-1.96*np.sqrt(markov_model.covars_[X_state])[:,0,0], markov_model.means_[X_state][:,0]+1.96*np.sqrt(markov_model.covars_[X_state])[:,0,0])\n",
    "plt.plot(markov_model.means_[X_state][:,0],'g*-',label=\"Prediccion de la media\")\n",
    "plt.plot(X,'ro-',label=\"Data\") #-- here put train or val\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "> e) Dado que se ve que el problema no puede ser modelado de manera adecuada con 3 estados distintos (valores que puede tomar el estado oculto en cada instante de tiempo, $s_t$). Experimente con variar la cantidad de éstos  ¿Qué sucede si aumenta hasta tener la misma cantidad de estados que la cantidad de datos? Visualice lo que estime conveniente, además de medir el *log-likelihood* en cada conjunto.\n",
    "```python\n",
    "n_states = np.arange(1,50)\n",
    "markov_model = hmm.GaussianHMM(n_components=n_state, n_iter=100)\n",
    "markov_model.fit(X_train)\n",
    "```\n",
    "\n",
    "\n",
    "> f) Debido a que el modelo no predice el valor continuo directamente, sino que predice el estado oculto de cada instante de tiempo, es necesario hacer un muestreo para obtener el valor continuo (o si desea, quedarse con la media). Realice este muestreo y evalúe la métrica de MSE (*Mean Square Error*) sobre el conjunto de pruebas.\n",
    "```python\n",
    "X_state = markov_model.predict(X_test) #predice el estado, no el valor\n",
    "X_output = norm( markov_model.means_[X_state], np.sqrt(markov_model.covars_[X_state][:,0]) ).rvs() #rvs is sample\n",
    "from  sklearn.metrics import mean_squared_error as mse\n",
    "mse(X_test, X_output)\n",
    "```\n",
    "\n",
    "> ¿Cambian mucho los resultados si se emplea una mezcla de gausianas como modelo para $p(x_t|s_t)$ en ves de que cada estado pertenezca a un único modelo Gausiano (distribución normal)?\n",
    "```python\n",
    "from hmmlearn.hmm import GMMHMM\n",
    "markov_model2 = GMMHMM(n_components=n_state, n_mix=3, n_iter=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] http://archive.ics.uci.edu/ml/datasets/Wine+Quality  \n",
    "[2] http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html  \n",
    "[3] http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html, http://colah.github.io/posts/2014-07-Understanding-Convolutions/    \n",
    "[4] https://www.vision.ee.ethz.ch/datasets_extra/food-101/  \n",
    "[5] Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976), *Time Series Analysis, Forecasting and Control*. Third Edition. Holden-Day. Series G.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
